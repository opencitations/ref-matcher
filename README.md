# Reference Matching Tool

Repository for a bibliographic reference matching tool designed to match references from Crossref JSON files against [OpenCitations Meta](https://opencitations.net/meta). It implements a heuristic-based approach, enabling the retrieval and validation of bibliographic metadata even in cases of incomplete or inconsistent citation records and generates comprehensive reports with detailed statistics.

## Table of Contents

- [Features](#features)
- [Architecture Overview](#architecture-overview)
- [Installation](#installation)
- [Configuration](#configuration)
- [Usage](#usage)
- [Workflow](#workflow)
- [Scoring System](#scoring-system)
- [Output Files](#output-files)
- [Logging System](#logging-system)
- [Error Handling](#error-handling)
- [Advanced Features](#advanced-features)
- [Troubleshooting](#troubleshooting)

---

## Features

- **Multi-Format Support**: Processes Crossref JSON and TEI XML files
- **Async Architecture**: Concurrent processing with asyncio and aiohttp for high performance
- **Intelligent SPARQL Matching**: 6 query strategies with early stopping when threshold is met
- **Sophisticated Scoring System**: Weighted scoring (max 48 points) based on DOI, title, authors, year, volume, and pages
- **GROBID Integration**: Enriches references using GROBID for unstructured text parsing
- **Comprehensive Logging**: Multi-file logging system with 5 specialized logs
- **Rate Limiting**: Token bucket algorithm (2.5 req/s, burst of 10)
- **Concurrent Processing**: Semaphore-controlled parallelism (10 concurrent references)
- **Dynamic Threshold**: Automatic threshold adjustment (90% trigger)
- **Detailed Statistics**: Match rates, field contributions, query type distribution

---

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Reference Matching Tool                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚      1. Reference Extraction Phase      â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚                â”‚
                      â–¼                â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚JSON/TEI Filesâ”‚  +  â”‚    GROBID    â”‚
            â”‚              â”‚     â”‚   Fallback   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚                 â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  2. Reference Normalization Phase       â”‚
            â”‚  - Clean titles, authors, DOIs          â”‚
            â”‚  - Normalize text (Unicode, accents)    â”‚
            â”‚  - Extract numeric fields (year, pages) â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  3. SPARQL Query Construction Phase     â”‚
            â”‚                                         â”‚
            â”‚  Query Execution (sequential):          â”‚
            â”‚  1. year_and_doi                        â”‚
            â”‚  2. doi_title                           â”‚
            â”‚  3. author_title                        â”‚
            â”‚  4. year_author_page                    â”‚
            â”‚  5. year_volume_page                    â”‚
            â”‚  6. year_author_volume                  â”‚
            â”‚                                         â”‚
            â”‚  Early stop when score >= threshold     â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  4. OpenCitations SPARQL Query Phase    â”‚
            â”‚  - Async query execution                â”‚
            â”‚  - Rate limiting                        â”‚
            â”‚  - Token bucket algorithm               â”‚
            â”‚  - Error handling                       â”‚
            â”‚  - Max 3 retries with backoff           â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  5. Candidate Scoring Phase             â”‚
            â”‚                                         â”‚
            â”‚  Scoring Components:                    â”‚
            â”‚  â”œâ”€ DOI Exact Match: 15 pts             â”‚
            â”‚  â”œâ”€ Title Similarity: 14-10 pts         â”‚
            â”‚  â”œâ”€ Author Match: 7 pts                 â”‚
            â”‚  â”œâ”€ Year Match: 1 pt                    â”‚
            â”‚  â”œâ”€ Volume Match: 3 pts                 â”‚
            â”‚  â””â”€ Page Match: 8 pts                   â”‚
            â”‚                                         â”‚
            â”‚  Threshold: 26/48 points (54.5%)        â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  6. Result Generation & Export Phase    â”‚
            â”‚  - CSV matched references               â”‚
            â”‚  - CSV unmatched references             â”‚
            â”‚  - HTML processing report               â”‚
            â”‚  - Statistics text file                 â”‚
            â”‚  - 5 specialized log files              â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Installation

### Requirements

- Python 3.8+
- GROBID (optional, for processing fallback)
- Internet connection (for OpenCitations SPARQL endpoint)

### Python Dependencies

```bash
pip install -r requirements.txt
```

## Usage

### Basic Usage

#### Process Crossref JSON File
```bash
python ReferenceMatchingTool.py crossref_references.json \
    --output output_file.csv \
    --threshold 26 \
    --use-grobid \
    --grobid-config grobid_config.json
```
#### Process TEI XML File

```bash
python ReferenceMatchingTool.py references.tei.xml \
    --output output_file.csv \
    --threshold 26 \
    --use-grobid \
    --grobid-config grobid_config.json
```
#### Process Directory (Batch Mode)
```bash
python ReferenceMatchingTool.py input_directory/ \
    --batch \
    --output output_directory/ \
    --threshold 26 \
    --use-grobid
```
#### Disable DOI_based query Usage
```bash
python ReferenceMatchingTool.py crossref_references.json \
    --output matches.csv \
    --no-doi
```
#### Adjust Rate Limiting and Burst Size
```bash
python ReferenceMatchingTool.py crossref_references.json \
    --output matches.csv \
    --rate-limit 1.5 \
    --burst-size 5
```

### Command-Line Arguments

| Argument | Type | Description | Default |
|----------|------|-------------|---------|
| `input` | str | **Required.** Path to input Crossref JSON or TEI XML file, or directory for batch processing | - |
| `--output, -o` | str | Output CSV file path (single mode) or directory (batch mode). Auto-generated if not specified | Auto-generated |
| `--threshold, -t` | int | Minimum matching score (0-48) required to consider a reference as matched. Lower = more permissive | 26 |
| `--use-grobid` | flag | Enable GROBID fallback to extract metadata from unstructured citation text when initial matching fails | False |
| `--grobid-config` | str | Path to GROBID configuration JSON file. If not specified, searches: current directory (`grobid_config.json`), `~/.grobid/config.json`, script directory, parent directories (up to 3 levels), and `GROBID_CONFIG_PATH` environment variable | None (auto-search) |
| `--batch, -b` | flag | Enable batch mode to process all JSON/XML files in the input directory concurrently | False |
| `--use-doi` | flag | Include DOI-based queries (year_and_doi, doi_title) in the matching strategy. Default enabled | True |
| `--no-doi` | flag | Disable DOI-based queries. Useful when DOI metadata is unreliable or missing | - |
| `--timeout` | int | Maximum time in seconds to wait for each SPARQL query response before timing out | 600 |
| `--max-retries` | int | Number of retry attempts for failed SPARQL queries (handles transient network errors) | 3 |
| `--batch-size` | int | Number of files to process simultaneously in each batch. Lower values reduce memory usage | 3 |
| `--pause-duration` | int | Delay in seconds between processing batches to avoid overwhelming the server | 10 |
| `--error-threshold` | int | Maximum number of consecutive server errors (5xx) before stopping batch processing | 10 |
| `--log-level` | str | Verbosity of logging output: DEBUG (detailed), INFO (standard), WARNING, or ERROR (minimal) | INFO |
| `--rate-limit` | float | Maximum SPARQL queries per second to respect OpenCitations API rate limits | 2.5 |
| `--burst-size` | int | Maximum number of concurrent requests allowed in token bucket before rate limiting kicks in | 10 |

---

## Workflow

### Detailed Processing Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 1: INPUT PROCESSING                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                            â”‚
â”‚               Crossref JSON       TEI XML File             â”‚
â”‚                    â”‚                    â”‚                  â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                               â–¼                            â”‚
â”‚                   Parse & Extract References               â”‚
â”‚                               â”‚                            â”‚
â”‚             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚             â–¼                                   â–¼          â”‚
â”‚       Crossref Format                      TEI Format      â”‚
â”‚       (JSON structure)                     (biblStruct)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 2: REFERENCE NORMALIZATION                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                            â”‚
â”‚  For each reference:                                       â”‚
â”‚  1. Clean title (remove punctuation, normalize case)       â”‚
â”‚  2. Normalize DOI (strip prefix, lowercase)                â”‚
â”‚  3. Extract authors (parse names, handle formats)          â”‚
â”‚  4. Validate year (check range 1700-current+1)             â”‚
â”‚  5. Normalize Unicode (remove accents, special chars)      â”‚
â”‚  6. Extract volume/page numbers                            â”‚
â”‚                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 3: QUERY STRATEGY SELECTION                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                            â”‚
â”‚  Query Execution Order (sequential, early stop):           â”‚
â”‚                                                            â”‚
â”‚  1. year_and_doi (if DOI + year available)                 â”‚
â”‚  2. doi_title (if DOI + title available)                   â”‚
â”‚  3. author_title (if author + title available)             â”‚
â”‚  4. year_author_page (if year + author + page available)   â”‚
â”‚  5. year_volume_page (if year + volume + page available)   â”‚
â”‚  6. year_author_volume (if year + author + vol available)  â”‚
â”‚                                                            â”‚
â”‚  Early stop when: score >= threshold                       â”‚
â”‚  Grobid fallback: if initial match fails                   â”‚
â”‚  No-year attempt: if suspiscious year is found             â”‚
â”‚                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 4: SPARQL QUERY EXECUTION                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                            â”‚
â”‚  For selected query:                                       â”‚
â”‚  1. Construct SPARQL query with filters                    â”‚
â”‚  2. Apply rate limiting (2.5 req/sec)                      â”‚
â”‚  3. Execute query against OpenCitations endpoint           â”‚
â”‚  4. Handle errors:                                         â”‚
â”‚     - 429 (Rate Limit): Exponential backoff                â”‚
â”‚     - 5xx (Server Error): Retry with delay                 â”‚
â”‚     - Timeout: Retry with extended timeout                 â”‚
â”‚  5. Parse results (extract candidates)                     â”‚
â”‚                                                            â”‚
â”‚  Max retries: 3                                            â”‚
â”‚  Timeout: 600 seconds                                      â”‚
â”‚                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 5: CANDIDATE SCORING                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                            â”‚
â”‚  For each candidate from SPARQL results:                   â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚ DOI Matching (15 points max)            â”‚               â”‚
â”‚  â”‚ - Exact match: +15 pts                  â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚ Title Similarity (14 points max)        â”‚               â”‚
â”‚  â”‚ - 100% match: +14 pts                   â”‚               â”‚
â”‚  â”‚ - 95-99%:     +13 pts                   â”‚               â”‚
â”‚  â”‚ - 90-94%:     +13 pts                   â”‚               â”‚
â”‚  â”‚ - 85-89%:     +12 pts                   â”‚               â”‚
â”‚  â”‚ - 80-84%:     +11 pts                   â”‚               â”‚
â”‚  â”‚ - 75-79%:     +10 pts                   â”‚               â”‚
â”‚  â”‚ - <75%:       +0 pts                    â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚ Author Matching (7 points max)          â”‚               â”‚
â”‚  â”‚ - Any exact surname match: +7 pts       â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚ Year Matching (1 point max)             â”‚               â”‚
â”‚  â”‚ - Exact year: +1 pt                     â”‚               â”‚
â”‚  â”‚ - Adjacent:   +0 pts                    â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚ Volume Matching (3 points max)          â”‚               â”‚
â”‚  â”‚ - Exact match: +3 pts                   â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚ Page Matching (8 points max)            â”‚               â”‚
â”‚  â”‚ - Start OR End page match: +8 pts       â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                            â”‚
â”‚  TOTAL SCORE: Sum of all components (max 48 points)        â”‚
â”‚  THRESHOLD: 26 points (54.5% of maximum)                   â”‚
â”‚  ADJUSTED THRESHOLD: 90% of 26                             â”‚
â”‚                                                            â”‚
â”‚  Select early-winning candidate with score >= 90% of 26    â”‚
â”‚                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 6: RESULT COMPILATION & OUTPUT                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                            â”‚
â”‚  Generate outputs:                                         â”‚
â”‚                                                            â”‚
â”‚  1. CSV Matched References                                 â”‚
â”‚     - reference_id, article_title                          â”‚
â”‚     - matched_title, score                                 â”‚
â”‚     - matched_doi, meta_id                                 â”‚
â”‚     - query_type                                           â”‚
â”‚                                                            â”‚
â”‚  2. CSV Unmatched References                               â”‚
â”‚     - All reference metadata                               â”‚
â”‚     - Best score achieved                                  â”‚
â”‚     - Score breakdown (original/grobid/no-year)            â”‚
â”‚     - GROBID attempt status                                â”‚
â”‚                                                            â”‚
â”‚  3. Statistics Text File                                   â”‚
â”‚     - Total references, match rate                         â”‚
â”‚     - Field availability stats                             â”‚
â”‚     - Query type distribution                              â”‚
â”‚     - GROBID fallback statistics                           â”‚
â”‚                                                            â”‚
â”‚  4. Log Files (5 specialized logs)                         â”‚
â”‚     - reference_matching_main.log                          â”‚
â”‚     - reference_matching_authors.log                       â”‚
â”‚     - reference_matching_queries.log                       â”‚
â”‚     - reference_matching_scores.log                        â”‚
â”‚     - reference_matching_errors.log                        â”‚
â”‚                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---
### Scoring Logic Examples

#### Example 1: Perfect Match (48/48 points)

```
Reference Input:
  Title: "Deep Learning in Medical Imaging"
  DOI: 10.1234/example.2020.001
  Authors: ["Smith, J.", "Johnson, M."]
  Year: 2020
  Volume: 15
  Pages: 123-145

OpenCitations Candidate:
  Title: "Deep Learning in Medical Imaging"
  DOI: 10.1234/example.2020.001
  Authors: ["Smith, John", "Johnson, Mary"]
  Year: 2020
  Volume: 15
  Start Page: 123
  End Page: 145

Score Calculation:
  âœ“ DOI exact match:        +15 points
  âœ“ Title 100% match:       +14 points
  âœ“ Author match (Smith):   +7 points
  âœ“ Year exact:             +1 point
  âœ“ Volume match:           +3 points
  âœ“ Page match (123):       +8 points
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  TOTAL:                    48 points âœ“ MATCH
```

#### Example 2: Strong Match (31/48 points)

```
Reference Input:
  Title: "Machine learning techniques"
  Authors: ["Doe, A."]
  Year: 2019
  Volume: 12
  Pages: 45-67

OpenCitations Candidate:
  Title: "Machine Learning Techniques for Data Analysis"
  Authors: ["Doe, Alice", "Brown, Bob"]
  Year: 2019
  Volume: 12
  Start Page: 45

Score Calculation:
  âœ— DOI not available:      +0 points
  âœ“ Title 85% match:        +12 points
  âœ“ Author match (Doe):     +7 points
  âœ“ Year exact:             +1 point
  âœ“ Volume match:           +3 points
  âœ“ Page match (45):        +8 points
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  TOTAL:                    31 points âœ“ MATCH
```

#### Example 3: Weak Match (12/48 points)

```
Reference Input:
  Title: "Quantum computing review"
  Year: 2021

OpenCitations Candidate:
  Title: "A Comprehensive Review of Quantum Computing"
  Year: 2021

Score Calculation:
  âœ— DOI not available:      +0 points
  âœ“ Title 80% match:        +11 points
  âœ— No author data:         +0 points
  âœ“ Year exact:             +1 point
  âœ— No volume:              +0 points
  âœ— No page:                +0 points
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  TOTAL:                    12 points âœ— NO MATCH
```

---

## Output Files

### 1. CSV Results File

Tabular format for matched references:

```csv
reference_id,article_title,matched_title,score,matched_doi,meta_id,query_type
ref_1,"Machine Learning in Healthcare","Machine Learning in Healthcare Applications",35,"10.1234/mlh.2020","https://opencitations.net/meta/br/...",author_title
ref_3,"Neural Networks in Medicine","Neural Networks in Medical Imaging",42,"10.5678/nnm.2021","https://opencitations.net/meta/br/...",doi_title
```

### 2. Unmatched References CSV

References that didn't meet the threshold:

```csv
reference_id,year,volume,first_page,first_author_lastname,article_title,volume_title,journal_title,doi,unstructured,best_score,score_original,score_after_grobid,score_without_year,grobid_attempted,threshold_failed
ref_2,2019,12,45,Doe,"Deep Learning Review",,,10.9999/dlr.2019,,12,12,N/A,N/A,No,Yes
```

### 3. Statistics File

Text file with comprehensive statistics:

```txt
Total references: 25
Matches found: 18 (72.0%)
Errors: 0

References with author: 22/25
References with title: 25/25
References with DOI: 15/25
References with year: 24/25
References with volume: 20/25
References with page: 18/25

Query Type Distribution:
  author_title: 8 (44.4%)
  year_and_doi: 6 (33.3%)
  year_volume_page: 4 (22.2%)

GROBID fallbacks attempted: 3
GROBID successes: 2
```

### 4. HTML Processing Report

HTML report with comprehensive statistics, field contributions, query type distribution, and visualizations (generated as `processing_report.html`).

---

## Logging System

### Multi-File Logging Architecture

The tool uses 5 specialized log files for different aspects:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      LOG FILES STRUCTURE                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  1. reference_matching_main.log                             â”‚
â”‚     â”œâ”€ All processing events                                â”‚
â”‚     â”œâ”€ Initialization messages                              â”‚
â”‚     â”œâ”€ Progress updates                                     â”‚
â”‚     â””â”€ General workflow logs                                â”‚
â”‚                                                             â”‚
â”‚  2. reference_matching_authors.log                          â”‚
â”‚     â”œâ”€ Author extraction details                            â”‚
â”‚     â”œâ”€ Name parsing and normalization                       â”‚
â”‚     â”œâ”€ Author matching results                              â”‚
â”‚     â””â”€ Filter: Messages containing "AUTHOR" or "ğŸ‘¤"         â”‚ 
â”‚                                                             â”‚
â”‚  3. reference_matching_queries.log                          â”‚
â”‚     â”œâ”€ SPARQL query construction                            â”‚
â”‚     â”œâ”€ Query execution details                              â”‚
â”‚     â”œâ”€ API response summaries                               â”‚
â”‚     â””â”€ Filter: Messages containing "SPARQL", "QUERY",       â”‚ 
â”‚        "ğŸ”", or "ğŸ”¨"                                       â”‚
â”‚                                                             â”‚
â”‚  4. reference_matching_scores.log                           â”‚
â”‚     â”œâ”€ Score calculation details                            â”‚
â”‚     â”œâ”€ Field-by-field scoring                               â”‚
â”‚     â”œâ”€ Match/no-match decisions                             â”‚
â”‚     â””â”€ Filter: Messages containing "SCORE", "MATCH", "ğŸ¯"   â”‚
â”‚                                                             â”‚
â”‚  5. reference_matching_errors.log                           â”‚
â”‚     â”œâ”€ All WARNING and ERROR messages                       â”‚
â”‚     â”œâ”€ Exception tracebacks                                 â”‚
â”‚     â”œâ”€ API failures                                         â”‚
â”‚     â””â”€ Validation errors                                    â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Log Rotation

- Each log file has a maximum size of 10 MB
- Keeps 5 backup files (rotating)
- UTF-8 encoding for international characters
- Automatic timestamp and line number tracking

### Sample Log Entries

```
2025-11-07 14:23:15 - INFO - [match_reference:1234] - Starting match for reference #1
2025-11-07 14:23:15 - DEBUG - [normalize_doi:567] - ğŸ”¨ Normalized DOI: 10.1234/example
2025-11-07 14:23:16 - INFO - [execute_sparql_query:890] - ğŸ” QUERY: author_title
2025-11-07 14:23:17 - DEBUG - [calculate_score:1112] - ğŸ¯ SCORE: DOI=15, Title=13, Author=7
2025-11-07 14:23:17 - INFO - [match_reference:1245] - âœ“ MATCH found with score 35/48
```

---

## Error Handling

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ERROR HANDLING MATRIX                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Error Type       â”‚ Recovery Strategy                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Rate Limit (429) â”‚ â€¢ Exponential backoff: min(60, 2^n * 5s) â”‚
â”‚                  â”‚ â€¢ Reset token bucket to 0                â”‚
â”‚                  â”‚ â€¢ Max 3 retries                          â”‚
â”‚                  â”‚ â€¢ Log retry attempts and wait time       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Server Error     â”‚ â€¢ Retry with exponential backoff + jitterâ”‚
â”‚ (500, 502, 503,  â”‚ â€¢ Wait: 2^attempt + random(0, 1) seconds â”‚
â”‚ 504)             â”‚ â€¢ Max 3 retries                          â”‚
â”‚                  â”‚ â€¢ Log server status and response         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Timeout          â”‚ â€¢ Retry with fixed 2s delay              â”‚
â”‚                  â”‚ â€¢ Same timeout value on each retry       â”‚
â”‚                  â”‚ â€¢ Max 3 retries                          â”‚
â”‚                  â”‚ â€¢ Log timeout occurrence                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Network Error    â”‚ â€¢ Exponential backoff: 2^attempt seconds â”‚
â”‚ (ClientError)    â”‚ â€¢ Max 3 retries                          â”‚
â”‚                  â”‚ â€¢ Log network error details              â”‚
â”‚                  â”‚ â€¢ Raise QueryExecutionError if persistentâ”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ GROBID Failure   â”‚ â€¢ Log extraction failure/error           â”‚
â”‚                  â”‚ â€¢ Continue without GROBID enrichment     â”‚
â”‚                  â”‚ â€¢ Mark as unmatched if all attempts fail â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ JSON Parse Error â”‚ â€¢ Try multiple encodings (utf-8, latin-1)â”‚
â”‚ (Input file)     â”‚ â€¢ Log encoding and parse errors          â”‚
â”‚                  â”‚ â€¢ Raise error if all encodings fail      â”‚
â”‚                  â”‚ â€¢ No retry for malformed input files     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ JSON Parse Error â”‚ â€¢ Caught by generic Exception handler    â”‚
â”‚ (SPARQL response)â”‚ â€¢ Exponential backoff: 2^attempt seconds â”‚
â”‚                  â”‚ â€¢ Max 3 retries                          â”‚
â”‚                  â”‚ â€¢ Log error type and message             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
---

## Troubleshooting

### Common Issues and Solutions

#### Issue 1: Low Match Rate

```
Symptom: Match rate < 30%
Possible causes:
  âœ— Incomplete reference metadata
  âœ— Non-standard citation formats
  âœ— References not in OpenCitations
  âœ— PDF extraction errors

Solutions:
  âœ“ Check reference quality in input
  âœ“ Verify DOIs are correct
  âœ“ Enable GROBID fallback
  âœ“ Review author extraction logs
  âœ“ Try different query strategies
```

#### Issue 2: Rate Limiting Errors

```
Symptom: Frequent 429 errors
Possible causes:
  âœ— Too many concurrent requests
  âœ— Insufficient pause between batches

Solutions:
  âœ“ Reduce requests_per_second
  âœ“ Increase pause_duration
  âœ“ Reduce batch_size
  âœ“ Check rate limiting logs
```

#### Issue 3: GROBID Connection Failed

```
Symptom: "Cannot connect to GROBID server"
Possible causes:
  âœ— GROBID server not running
  âœ— Wrong server URL in config
  âœ— Network/firewall issues

Solutions:
  âœ“ Start GROBID server: docker run -d -p 8070:8070 grobid/grobid
  âœ“ Check grobid_config.json URL
  âœ“ Test connection: curl http://localhost:8070/api/isalive
```

#### Issue 4: Encoding Errors

```
Symptom: UnicodeDecodeError or garbled text
Possible causes:
  âœ— Non-UTF-8 input files
  âœ— Special characters in titles

Solutions:
  âœ“ Save input CSV as UTF-8
  âœ“ Enable text normalization
  âœ“ Check log files for details
  âœ“ Use unidecode for accents
```

## Performance Tips

### Optimizing Match Rates

1. **Complete Metadata**: Input data with complete metadata have a higher chance to match
2. **Standardized Formats**: Input data that follows standard citation formats have a higher chance to match
3. **Enable GROBID**: Better extraction for difficult documents
4. **Adjust Threshold**: Lower threshold (e.g., 22) for more matches (precision/recall tradeoff)

### Optimizing Speed

1. **Batch Processing**: Default batch_size is 3, can be increased for higher throughput
2. **Concurrent Queries**: Increase max_concurrent_queries (carefully, could actually slow down the process due to multiple errors)
3. **Checkpoint Frequently**: Save progress every 25-50 references
4. **Skip Slow Queries**: Set shorter timeouts for faster queries (precision/recall tradeoff)

---
