# Reference Matching Tool

Repository for a bibliographic reference matching tool designed to identify and align references between [Crossref](https://www.crossref.org/) and [OpenCitations Meta](https://opencitations.net/meta). It implements a heuristic-based approach, enabling the retrieval and validation of bibliographic metadata even in cases of incomplete or inconsistent citation records and generates comprehensive reports with detailed statistics.

## Table of Contents

- [Features](#features)
- [Architecture Overview](#architecture-overview)
- [Installation](#installation)
- [Configuration](#configuration)
- [Usage](#usage)
- [Workflow](#workflow)
- [Scoring System](#scoring-system)
- [Output Files](#output-files)
- [Logging System](#logging-system)
- [Error Handling](#error-handling)
- [Advanced Features](#advanced-features)
- [Troubleshooting](#troubleshooting)

---

## Features

- **Multi-source Reference Extraction**: Extracts references using Crossref API and GROBID fallback
- **Intelligent SPARQL Matching**: Uses multiple query strategies to find matches in OpenCitations
- **Sophisticated Scoring System**: Weighted scoring based on DOI, title, authors, year, volume, and pages
- **Comprehensive Logging**: Multi-file logging system with specialized logs for queries, authors, scores, and errors
- **Batch Processing**: Process multiple references with checkpointing and error recovery
- **HTML Reports**: Beautiful, interactive HTML reports with detailed statistics
- **Rate Limiting**: Built-in rate limiting to respect API constraints
- **Concurrent Processing**: Async operations for improved performance

---

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Reference Matching Tool                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚      1. Reference Extraction Phase      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                â”‚
                    â–¼                â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Crossref    â”‚    â”‚    GROBID    â”‚
         â”‚     API      â”‚    â”‚   Fallback   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                             â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚     2. Reference Normalization Phase    â”‚
        â”‚  - Clean titles, authors, DOIs          â”‚
        â”‚  - Normalize text (Unicode, accents)    â”‚
        â”‚  - Extract numeric fields (year, pages) â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚    3. SPARQL Query Construction Phase   â”‚
        â”‚                                         â”‚
        â”‚  Strategy Selection (in order):         â”‚
        â”‚  â”œâ”€ DOI + Title (if DOI available)      â”‚
        â”‚  â”œâ”€ Year + DOI (if both available)      â”‚
        â”‚  â”œâ”€ Author + Title (primary)            â”‚
        â”‚  â”œâ”€ Year + Author + Page                â”‚
        â”‚  â”œâ”€ Year + Volume + Page                â”‚
        â”‚  â””â”€ Year + Author + Volume              â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   4. OpenCitations SPARQL Query Phase   â”‚
        â”‚  - Execute queries with retry logic     â”‚
        â”‚  - Rate limiting (2.5 req/sec)          â”‚
        â”‚  - Error handling (429, 5xx)            â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚      5. Candidate Scoring Phase         â”‚
        â”‚                                         â”‚
        â”‚  Scoring Components:                    â”‚
        â”‚  â”œâ”€ DOI Exact Match: 15 pts             â”‚
        â”‚  â”œâ”€ Title Similarity: 10-14 pts         â”‚
        â”‚  â”œâ”€ Author Match: 7 pts                 â”‚
        â”‚  â”œâ”€ Year Match: 1 pt                    â”‚
        â”‚  â”œâ”€ Volume Match: 3 pts                 â”‚
        â”‚  â””â”€ Page Match: 8 pts                   â”‚
        â”‚                                         â”‚
        â”‚  Threshold: 26/48 points (54%)          â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚    6. Result Generation & Export Phase  â”‚
        â”‚  - JSON results with match details      â”‚
        â”‚  - CSV summary reports                  â”‚
        â”‚  - HTML interactive dashboard           â”‚
        â”‚  - Detailed log files                   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Installation

### Requirements

- Python 3.8+
- GROBID server (optional, for PDF processing fallback)
- Internet connection (for OpenCitations SPARQL endpoint)

### Python Dependencies

```bash
pip install -r requirements.txt
```

## Configuration

### MatcherConfig Class

The tool uses a configuration class with sensible defaults:

```python
@dataclass
class MatcherConfig:
    # Timeouts and retries
    default_timeout: int = 600
    max_retries: int = 3
    
    # Year validation
    min_year: int = 1700
    max_year: int = current_year + 1
    
    # Scoring weights
    doi_exact_score: int = 15
    author_exact_match_score: int = 7
    title_exact_score: int = 14
    title_95_score: int = 13
    title_90_score: int = 13
    title_85_score: int = 12
    title_80_score: int = 11
    title_75_score: int = 10
    year_exact_score: int = 1
    volume_match_score: int = 3
    page_match_score: int = 8
    
    # Matching threshold
    matching_threshold: int = 26  # out of 48 max points
    
    # Rate limiting
    requests_per_second: float = 2.5
    burst_size: int = 10
    
    # Batch processing
    default_batch_size: int = 3
    checkpoint_interval: int = 10
```

### GROBID Configuration

Create a `grobid_config.json` file:

```json
{
  "grobid_server": "http://localhost:8070",
  "batch_size": 1000,
  "sleep_time": 5,
  "timeout": 60,
  "coordinates": ["persName"]
}
```

---

## Usage

### Basic Usage

#### Single Reference Matching

```python
from ReferenceMatchingToolBackupMod import ReferenceMatchingTool

# Initialize tool
tool = ReferenceMatchingTool()

# Match a single reference
reference = {
    "title": "Machine learning in bioinformatics",
    "year": "2020",
    "authors": ["Smith, J.", "Doe, A."],
    "doi": "10.1234/example"
}

result = tool.match_reference(reference)
print(f"Match found: {result['match_found']}")
print(f"Score: {result['match_score']}")
print(f"OpenCitations URI: {result['opencitations_uri']}")
```

#### Batch Processing from CSV

```python
# Process references from CSV file
tool.process_references_from_csv(
    input_csv="references.csv",
    output_json="results.json"
)
```

#### Process PDF with DOI

```python
# Extract and match references from a PDF
results = tool.match_references_from_pdf(
    doi="10.1234/article.doi",
    output_prefix="my_paper"
)
```

### Command Line Interface

```bash
# Process a single PDF by DOI
python ReferenceMatchingToolBackupMod.py \
    --doi "10.1234/article.doi" \
    --output-prefix "results"

# Process multiple PDFs from a directory
python ReferenceMatchingToolBackupMod.py \
    --pdf-dir "/path/to/pdfs" \
    --output-dir "/path/to/output"

# Custom batch size and pause
python ReferenceMatchingToolBackupMod.py \
    --doi "10.1234/article.doi" \
    --batch-size 5 \
    --pause-duration 15
```

### Command Line Arguments

| Argument | Description | Default |
|----------|-------------|---------|
| `--doi` | DOI of the article to process | None |
| `--pdf-path` | Direct path to PDF file | None |
| `--pdf-dir` | Directory containing PDFs | None |
| `--output-prefix` | Prefix for output files | "reference_matching" |
| `--output-dir` | Directory for output files | Current directory |
| `--batch-size` | Number of refs per batch | 3 |
| `--pause-duration` | Seconds to pause between batches | 10 |
| `--use-grobid-fallback` | Enable GROBID fallback | True |
| `--grobid-config` | Path to GROBID config | "grobid_config.json" |

---

## Workflow

### Detailed Processing Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 1: INPUT PROCESSING                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                            â”‚
â”‚  CSV Input           PDF Input (DOI)      PDF Input (File) â”‚
â”‚      â”‚                    â”‚                      â”‚         â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                           â–¼                                â”‚
â”‚              Parse & Extract References                    â”‚
â”‚                           â”‚                                â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚         â–¼                 â–¼                 â–¼              â”‚
â”‚   Via Crossref      Via GROBID        Manual CSV           â”‚ 
â”‚   (Primary)         (Fallback)        (Direct)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 2: REFERENCE NORMALIZATION                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                            â”‚
â”‚  For each reference:                                       â”‚
â”‚  1. Clean title (remove punctuation, normalize case)       â”‚
â”‚  2. Normalize DOI (strip prefix, lowercase)                â”‚
â”‚  3. Extract authors (parse names, handle formats)          â”‚
â”‚  4. Validate year (check range 1700-current+1)             â”‚
â”‚  5. Normalize Unicode (remove accents, special chars)      â”‚
â”‚  6. Extract volume/page numbers                            â”‚
â”‚                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 3: QUERY STRATEGY SELECTION                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                            â”‚
â”‚  Decision Tree:                                            â”‚
â”‚                                                            â”‚
â”‚  Has DOI + Title? â”€â”€Yesâ”€â”€> Use: DOI_TITLE query            â”‚
â”‚       â”‚                                                    â”‚
â”‚       No                                                   â”‚
â”‚       â”‚                                                    â”‚
â”‚  Has Year + DOI? â”€â”€Yesâ”€â”€> Use: YEAR_AND_DOI query          â”‚
â”‚       â”‚                                                    â”‚
â”‚       No                                                   â”‚
â”‚       â”‚                                                    â”‚
â”‚  Has Author + Title? â”€â”€Yesâ”€â”€> Use: AUTHOR_TITLE query      â”‚
â”‚       â”‚                                                    â”‚
â”‚       No                                                   â”‚
â”‚       â”‚                                                    â”‚
â”‚  Has Year + Author + Page? â”€â”€Yesâ”€â”€> Use: Y_A_P query       â”‚
â”‚       â”‚                                                    â”‚
â”‚       No                                                   â”‚
â”‚       â”‚                                                    â”‚
â”‚  Has Year + Volume + Page? â”€â”€Yesâ”€â”€> Use: Y_V_P query       â”‚
â”‚       â”‚                                                    â”‚
â”‚       No                                                   â”‚
â”‚       â”‚                                                    â”‚
â”‚  Has Year + Author + Vol? â”€â”€Yesâ”€â”€> Use: Y_A_V query        â”‚
â”‚       â”‚                                                    â”‚
â”‚       No â”€â”€â”€â”€â”€â”€> SKIP (insufficient metadata)              â”‚
â”‚                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 4: SPARQL QUERY EXECUTION                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                            â”‚
â”‚  For selected query:                                       â”‚
â”‚  1. Construct SPARQL query with filters                    â”‚
â”‚  2. Apply rate limiting (2.5 req/sec)                      â”‚
â”‚  3. Execute query against OpenCitations endpoint           â”‚
â”‚  4. Handle errors:                                         â”‚
â”‚     - 429 (Rate Limit): Exponential backoff                â”‚
â”‚     - 5xx (Server Error): Retry with delay                 â”‚
â”‚     - Timeout: Retry with extended timeout                 â”‚
â”‚  5. Parse results (extract candidates)                     â”‚
â”‚                                                            â”‚
â”‚  Max retries: 3                                            â”‚
â”‚  Timeout: 600 seconds                                      â”‚
â”‚                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 5: CANDIDATE SCORING                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                            â”‚
â”‚  For each candidate from SPARQL results:                   â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚ DOI Matching (15 points max)            â”‚               â”‚
â”‚  â”‚ - Exact match: +15 pts                  â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚ Title Similarity (14 points max)        â”‚               â”‚
â”‚  â”‚ - 100% match: +14 pts                   â”‚               â”‚
â”‚  â”‚ - 95-99%:     +13 pts                   â”‚               â”‚
â”‚  â”‚ - 90-94%:     +13 pts                   â”‚               â”‚
â”‚  â”‚ - 85-89%:     +12 pts                   â”‚               â”‚
â”‚  â”‚ - 80-84%:     +11 pts                   â”‚               â”‚
â”‚  â”‚ - 75-79%:     +10 pts                   â”‚               â”‚
â”‚  â”‚ - <75%:       +0 pts                    â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚ Author Matching (7 points max)          â”‚               â”‚
â”‚  â”‚ - Any exact surname match: +7 pts       â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚ Year Matching (1 point max)             â”‚               â”‚
â”‚  â”‚ - Exact year: +1 pt                     â”‚               â”‚
â”‚  â”‚ - Adjacent:   +0 pts                    â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚ Volume Matching (3 points max)          â”‚               â”‚
â”‚  â”‚ - Exact match: +3 pts                   â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚ Page Matching (8 points max)            â”‚               â”‚
â”‚  â”‚ - Start OR End page match: +8 pts       â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                            â”‚
â”‚  TOTAL SCORE: Sum of all components (max 48 points)        â”‚
â”‚  THRESHOLD: 26 points (54% of maximum)                     â”‚
â”‚                                                            â”‚
â”‚  Select candidate with highest score >= 26                 â”‚
â”‚                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 6: RESULT COMPILATION & OUTPUT                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                            â”‚
â”‚  Generate outputs:                                         â”‚
â”‚                                                            â”‚
â”‚  1. JSON Results File                                      â”‚
â”‚     - All reference details                                â”‚
â”‚     - Match scores and URIs                                â”‚
â”‚     - Query types used                                     â”‚
â”‚     - Timestamp and metadata                               â”‚
â”‚                                                            â”‚
â”‚  2. CSV Summary File                                       â”‚
â”‚     - Reference ID, Title                                  â”‚
â”‚     - Match Found (Yes/No)                                 â”‚
â”‚     - Match Score                                          â”‚
â”‚     - OpenCitations URI                                    â”‚
â”‚     - Query Type                                           â”‚
â”‚                                                            â”‚
â”‚  3. HTML Report                                            â”‚
â”‚     - Interactive dashboard                                â”‚
â”‚     - Statistics and charts                                â”‚
â”‚     - Field contribution analysis                          â”‚
â”‚     - Links to log files                                   â”‚
â”‚                                                            â”‚
â”‚  4. Log Files (5 specialized logs)                         â”‚
â”‚     - Main processing log                                  â”‚
â”‚     - Author extraction log                                â”‚
â”‚     - SPARQL query log                                     â”‚
â”‚     - Score calculation log                                â”‚
â”‚     - Error log                                            â”‚
â”‚                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Scoring System

### Scoring Components (Maximum: 48 points)

The scoring system is designed to balance multiple metadata fields:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SCORING BREAKDOWN                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  Component          â”‚ Max Points â”‚ Weight â”‚ Description â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚  DOI Match          â”‚     15     â”‚  31.2% â”‚ Strongest   â”‚
â”‚  Title Similarity   â”‚     14     â”‚  29.2% â”‚ Very Strong â”‚
â”‚  Page Match         â”‚      8     â”‚  16.7% â”‚ Strong      â”‚
â”‚  Author Match       â”‚      7     â”‚  14.6% â”‚ Moderate    â”‚
â”‚  Volume Match       â”‚      3     â”‚   6.2% â”‚ Weak        â”‚
â”‚  Year Match         â”‚      1     â”‚   2.1% â”‚ Very Weak   â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚  TOTAL              â”‚     48     â”‚ 100.0% â”‚             â”‚
â”‚                                                         â”‚
â”‚  THRESHOLD: 26 points (54.2% of maximum)                â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Scoring Logic Examples

#### Example 1: Perfect Match (48/48 points)

```
Reference Input:
  Title: "Deep Learning in Medical Imaging"
  DOI: 10.1234/example.2020.001
  Authors: ["Smith, J.", "Johnson, M."]
  Year: 2020
  Volume: 15
  Pages: 123-145

OpenCitations Candidate:
  Title: "Deep Learning in Medical Imaging"
  DOI: 10.1234/example.2020.001
  Authors: ["Smith, John", "Johnson, Mary"]
  Year: 2020
  Volume: 15
  Start Page: 123
  End Page: 145

Score Calculation:
  âœ“ DOI exact match:        +15 points
  âœ“ Title 100% match:       +14 points
  âœ“ Author match (Smith):   +7 points
  âœ“ Year exact:             +1 point
  âœ“ Volume match:           +3 points
  âœ“ Page match (123):       +8 points
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  TOTAL:                    48 points âœ“ MATCH
```

#### Example 2: Strong Match (31/48 points)

```
Reference Input:
  Title: "Machine learning techniques"
  Authors: ["Doe, A."]
  Year: 2019
  Volume: 12
  Pages: 45-67

OpenCitations Candidate:
  Title: "Machine Learning Techniques for Data Analysis"
  Authors: ["Doe, Alice", "Brown, Bob"]
  Year: 2019
  Volume: 12
  Start Page: 45

Score Calculation:
  âœ— DOI not available:      +0 points
  âœ“ Title 85% match:        +12 points
  âœ“ Author match (Doe):     +7 points
  âœ“ Year exact:             +1 point
  âœ“ Volume match:           +3 points
  âœ“ Page match (45):        +8 points
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  TOTAL:                    31 points âœ“ MATCH
```

#### Example 3: Weak Match (12/48 points)

```
Reference Input:
  Title: "Quantum computing review"
  Year: 2021

OpenCitations Candidate:
  Title: "A Comprehensive Review of Quantum Computing"
  Year: 2021

Score Calculation:
  âœ— DOI not available:      +0 points
  âœ“ Title 80% match:        +11 points
  âœ— No author data:         +0 points
  âœ“ Year exact:             +1 point
  âœ— No volume:              +0 points
  âœ— No page:                +0 points
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  TOTAL:                    12 points âœ— NO MATCH
```

---

## Output Files

### 1. JSON Results File

Complete matching results with all metadata:

```json
{
  "metadata": {
    "total_references": 25,
    "matched": 18,
    "unmatched": 7,
    "match_rate": 72.0,
    "processing_time": "00:05:32"
  },
  "references": [
    {
      "ref_id": 1,
      "original_title": "Machine Learning in Healthcare",
      "normalized_title": "machine learning in healthcare",
      "doi": "10.1234/mlh.2020",
      "year": 2020,
      "authors": ["Smith, J.", "Doe, A."],
      "match_found": true,
      "match_score": 35,
      "opencitations_uri": "https://opencitations.net/id/...",
      "query_type": "author_title",
      "matched_candidate": {
        "title": "Machine Learning in Healthcare Applications",
        "doi": "10.1234/mlh.2020",
        "authors": ["Smith, John", "Doe, Alice"],
        "year": 2020,
        "volume": "15",
        "pages": "123-145"
      },
      "score_breakdown": {
        "doi_score": 15,
        "title_score": 13,
        "author_score": 7,
        "year_score": 1,
        "volume_score": 0,
        "page_score": 0
      }
    }
  ]
}
```

### 2. CSV Summary File

Tabular format for easy analysis:

```csv
ref_id,title,match_found,match_score,opencitations_uri,query_type
1,"Machine Learning in Healthcare",Yes,35,"https://opencitations.net/id/...",author_title
2,"Deep Learning Review",No,0,"",""
3,"Neural Networks in Medicine",Yes,42,"https://opencitations.net/id/...",doi_title
```

### 3. HTML Report

Interactive dashboard with:
- **Overview Statistics**: Match rate, total references, processing time
- **Query Type Breakdown**: Which query strategies were used
- **Field Contribution Analysis**: How each metadata field contributed to matches
- **Match Score Distribution**: Histogram of score distribution
- **Author Statistics**: Author extraction and matching success
- **Volume/Page Statistics**: Availability and match rates
- **GROBID Fallback Stats**: Success rate of GROBID processing
- **Log File Links**: Quick access to specialized logs

---

## Logging System

### Multi-File Logging Architecture

The tool uses 5 specialized log files for different aspects:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      LOG FILES STRUCTURE                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  1. reference_matching_main.log                             â”‚
â”‚     â”œâ”€ All processing events                                â”‚
â”‚     â”œâ”€ Initialization messages                              â”‚
â”‚     â”œâ”€ Progress updates                                     â”‚
â”‚     â””â”€ General workflow logs                                â”‚
â”‚                                                             â”‚
â”‚  2. reference_matching_authors.log                          â”‚
â”‚     â”œâ”€ Author extraction details                            â”‚
â”‚     â”œâ”€ Name parsing and normalization                       â”‚
â”‚     â”œâ”€ Author matching results                              â”‚
â”‚     â””â”€ Filter: Messages containing "AUTHOR" or "ğŸ‘¤"         â”‚ 
â”‚                                                             â”‚
â”‚  3. reference_matching_queries.log                          â”‚
â”‚     â”œâ”€ SPARQL query construction                            â”‚
â”‚     â”œâ”€ Query execution details                              â”‚
â”‚     â”œâ”€ API response summaries                               â”‚
â”‚     â””â”€ Filter: Messages containing "SPARQL", "QUERY",       â”‚ 
â”‚        "ğŸ”", or "ğŸ”¨"                                       â”‚
â”‚                                                             â”‚
â”‚  4. reference_matching_scores.log                           â”‚
â”‚     â”œâ”€ Score calculation details                            â”‚
â”‚     â”œâ”€ Field-by-field scoring                               â”‚
â”‚     â”œâ”€ Match/no-match decisions                             â”‚
â”‚     â””â”€ Filter: Messages containing "SCORE", "MATCH", "ğŸ¯"   â”‚
â”‚                                                             â”‚
â”‚  5. reference_matching_errors.log                           â”‚
â”‚     â”œâ”€ All WARNING and ERROR messages                       â”‚
â”‚     â”œâ”€ Exception tracebacks                                 â”‚
â”‚     â”œâ”€ API failures                                         â”‚
â”‚     â””â”€ Validation errors                                    â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Log Rotation

- Each log file has a maximum size of 10 MB
- Keeps 5 backup files (rotating)
- UTF-8 encoding for international characters
- Automatic timestamp and line number tracking

### Sample Log Entries

```
2025-11-07 14:23:15 - INFO - [match_reference:1234] - Starting match for reference #1
2025-11-07 14:23:15 - DEBUG - [normalize_doi:567] - ğŸ”¨ Normalized DOI: 10.1234/example
2025-11-07 14:23:16 - INFO - [execute_sparql_query:890] - ğŸ” QUERY: author_title
2025-11-07 14:23:17 - DEBUG - [calculate_score:1112] - ğŸ¯ SCORE: DOI=15, Title=13, Author=7
2025-11-07 14:23:17 - INFO - [match_reference:1245] - âœ“ MATCH found with score 35/48
```

---

## Error Handling

### Error Types and Recovery Strategies

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ERROR HANDLING MATRIX                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Error Type       â”‚ Recovery Strategy                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Rate Limit (429) â”‚ â€¢ Exponential backoff                    â”‚
â”‚                  â”‚ â€¢ Wait time: 2^attempt seconds           â”‚
â”‚                  â”‚ â€¢ Max 3 retries                          â”‚
â”‚                  â”‚ â€¢ Log retry attempts                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Server Error     â”‚ â€¢ Retry with delay                       â”‚
â”‚ (500, 502, 503)  â”‚ â€¢ Increase timeout                       â”‚
â”‚                  â”‚ â€¢ Max 3 retries                          â”‚
â”‚                  â”‚ â€¢ Log server response                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Timeout          â”‚ â€¢ Extend timeout by 50%                  â”‚
â”‚                  â”‚ â€¢ Retry with new timeout                 â”‚
â”‚                  â”‚ â€¢ Log timeout duration                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Network Error    â”‚ â€¢ Check connection                       â”‚
â”‚                  â”‚ â€¢ Retry after 5 seconds                  â”‚
â”‚                  â”‚ â€¢ Log network state                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Invalid Data     â”‚ â€¢ Skip reference                         â”‚
â”‚                  â”‚ â€¢ Log validation error                   â”‚
â”‚                  â”‚ â€¢ Continue with next                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ GROBID Failure   â”‚ â€¢ Log extraction failure                 â”‚
â”‚                  â”‚ â€¢ Mark as unmatched                      â”‚
â”‚                  â”‚ â€¢ Continue processing                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ JSON Parse Error â”‚ â€¢ Log malformed response                 â”‚
â”‚                  â”‚ â€¢ Retry query                            â”‚
â”‚                  â”‚ â€¢ Skip if persistent                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Custom Exceptions

```python
ReferenceMatchingError       # Base exception
â”œâ”€ QueryExecutionError       # SPARQL query failures
â”‚  â”œâ”€ RateLimitError         # 429 responses
â”‚  â””â”€ ServerError            # 5xx responses
â””â”€ ValidationError           # Data validation errors
```

---

## Advanced Features

### 1. Batch Processing with Checkpoints

Process large sets of references with automatic progress saving:

```python
tool.process_references_from_csv(
    input_csv="large_dataset.csv",
    output_json="results.json",
    batch_size=10,              # Process 10 refs at a time
    pause_duration=15,          # Pause 15s between batches
    checkpoint_interval=50      # Save progress every 50 refs
)
```

**Checkpoint Recovery:**
If processing is interrupted, the tool automatically resumes from the last checkpoint.

### 2. Rate Limiting

Prevents overwhelming the OpenCitations API:

```python
# Token bucket algorithm
Requests per second: 2.5
Burst capacity: 10 requests
Refill rate: 1 token per 0.4 seconds
```

### 3. Concurrent Processing

Uses async operations for improved performance:

```python
# Concurrent SPARQL queries
max_concurrent_queries: 5
timeout_per_query: 600 seconds
connection_pool_size: 10
```

### 4. GROBID Fallback

Automatically uses GROBID if Crossref fails:

```python
# Fallback chain
1. Try Crossref API (fast, structured)
   â†“ (if fails)
2. Try GROBID server (slower, PDF parsing)
   â†“ (if fails)
3. Mark as extraction failure
```

### 5. Text Normalization Pipeline

Sophisticated text cleaning for better matching:

```python
# Normalization steps
1. Unicode normalization (NFD)
2. Accent removal (unidecode)
3. Lowercase conversion
4. Punctuation removal
5. Whitespace normalization
6. HTML entity decoding
```

---

## Troubleshooting

### Common Issues and Solutions

#### Issue 1: Low Match Rate

```
Symptom: Match rate < 30%
Possible causes:
  âœ— Incomplete reference metadata
  âœ— Non-standard citation formats
  âœ— References not in OpenCitations
  âœ— PDF extraction errors

Solutions:
  âœ“ Check reference quality in input
  âœ“ Verify DOIs are correct
  âœ“ Enable GROBID fallback
  âœ“ Review author extraction logs
  âœ“ Try different query strategies
```

#### Issue 2: Rate Limiting Errors

```
Symptom: Frequent 429 errors
Possible causes:
  âœ— Too many concurrent requests
  âœ— Insufficient pause between batches

Solutions:
  âœ“ Reduce requests_per_second
  âœ“ Increase pause_duration
  âœ“ Reduce batch_size
  âœ“ Check rate limiting logs
```

#### Issue 3: GROBID Connection Failed

```
Symptom: "Cannot connect to GROBID server"
Possible causes:
  âœ— GROBID server not running
  âœ— Wrong server URL in config
  âœ— Network/firewall issues

Solutions:
  âœ“ Start GROBID server: docker run -d -p 8070:8070 grobid/grobid
  âœ“ Check grobid_config.json URL
  âœ“ Test connection: curl http://localhost:8070/api/isalive
  âœ“ Disable GROBID: --use-grobid-fallback false
```

#### Issue 4: Memory Issues with Large Datasets

```
Symptom: Out of memory errors
Possible causes:
  âœ— Processing too many refs at once
  âœ— Large PDF files

Solutions:
  âœ“ Reduce batch_size to 1-3
  âœ“ Increase checkpoint_interval
  âœ“ Process PDFs separately
  âœ“ Split large CSV files
```

#### Issue 5: Encoding Errors

```
Symptom: UnicodeDecodeError or garbled text
Possible causes:
  âœ— Non-UTF-8 input files
  âœ— Special characters in titles

Solutions:
  âœ“ Save input CSV as UTF-8
  âœ“ Enable text normalization
  âœ“ Check log files for details
  âœ“ Use unidecode for accents
```

## Performance Tips

### Optimizing Match Rates

1. **Provide Complete Metadata**: Include DOI, authors, year, volume, and pages
2. **Use Standardized Formats**: Follow standard citation formats
3. **Clean Input Data**: Remove formatting artifacts before processing
4. **Enable GROBID**: Better PDF extraction for difficult documents
5. **Adjust Threshold**: Lower threshold (e.g., 22) for more matches (precision/recall tradeoff)

### Optimizing Speed

1. **Batch Processing**: Use batch_size=5-10 for optimal throughput
2. **Concurrent Queries**: Increase max_concurrent_queries (carefully)
3. **Local GROBID**: Run GROBID server locally for faster PDF processing
4. **Checkpoint Frequently**: Save progress every 25-50 references
5. **Skip Slow Queries**: Set shorter timeouts for faster queries

---

## ğŸ“„ License

This tool is provided as-is for academic and research purposes.

---

## ğŸ¤ Contributing

Contributions are welcome! Areas for improvement:
- Additional query strategies
- Machine learning-based scoring
- Support for additional databases
- Parallel processing optimization
- UI/dashboard improvements

---

## Support

For issues, questions, or feature requests:
1. Review log files for error details
2. Consult OpenCitations documentation
3. Raise an issue with detailed logs

---

## Version History

### Current Version
- Multi-file logging system
- DOI-based scoring (15 points)
- Enhanced HTML reports
- Async query execution
- Improved error handling
- GROBID fallback support
- Checkpoint recovery

---

**Happy Matching! ğŸ¯**
